# SCOUT

Structure-Aware Aspect and Anchor-Count Selection for Node Attribute Augmentation via Positional Information

**WWW 2026 (The Web Conference)**

SCOUT is a model-agnostic node attribute augmentation framework that improves
graph neural networks (GNNs) when node attributes are missing, sparse, or weak.


---

## ðŸ“Œ Introduction

**SCOUT** is a model-agnostic node attribute augmentation method that enhances the performance of graph neural networks (GNNs) by learning graph-aware positional information. It intelligently selects positional aspects and anchor counts to generate augmented node attributes, especially when original attributes are absent.

SCOUT addresses two core challenges in positional information (PI)-based augmentation:
1. Selecting appropriate structural measures and distance metrics.
2. Automatically determining the optimal number of anchor nodes (K).

To solve this, SCOUT:
- Learns a graph-level attention over diverse centralityâ€“similarity pairs (aspects).
- Uses an elbow detector over centrality rankings to determine anchor-count.
- Can be integrated into standard GNNs for tasks like node classification and link prediction.

ðŸ“„ **Paper Title**: *SCOUT: Structure-Aware Aspect and Anchor-Count Selection for Node Attribute Augmentation via Positional Information*  
ðŸ” **Submission**: WWW 2026 (under review)  
ðŸ“Ž **Repository**: https://github.com/seinkim2001/SCOUT

---

## ðŸ“‚ Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Features](#features)
- [Configuration](#configuration)
- [Dependencies](#dependencies)
- [Examples](#examples)
- [Contributors](#contributors)
- [License](#license)

---

## âš™ï¸ Installation

### Using Conda (recommended)
```bash
conda env create -f requirements_conda.yaml
conda activate scout
```

### Using pip
```bash
pip install -r requirements.txt
```

---

## ðŸš€ Usage

To run the core pipeline (e.g., link prediction), use the provided shell script:
```bash
bash scripts/run_linkpred.sh
```

Alternatively, you can run individual training scripts:
```bash
python src/core/train_linkpred.py
python src/core/train_nodeclf.py
```

---

## ðŸ§± Project Structure

```plaintext
SCOUT/
â”œâ”€â”€ attrs/                      # Precomputed centrality and similarity attributes
â”‚   â””â”€â”€ Cora_concat_centrality/
â”œâ”€â”€ datasets/                  # Graph datasets (e.g., Cora)
â”‚   â””â”€â”€ Cora/
â”œâ”€â”€ logs/                      # Training logs
â”œâ”€â”€ results/                   # Output results and evaluation metrics
â”œâ”€â”€ scripts/                   # Shell scripts for experiment automation
â”‚   â””â”€â”€ run_linkpred.sh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                  # Core training and preprocessing logic
â”‚   â”‚   â”œâ”€â”€ train_linkpred.py
â”‚   â”‚   â”œâ”€â”€ train_nodeclf.py
â”‚   â”‚   â”œâ”€â”€ elbow_selector.py
â”‚   â”‚   â””â”€â”€ generate_attributes.py
â”‚   â”œâ”€â”€ models/                # GNN encoder, decoder, attribute gating module
â”‚   â”‚   â”œâ”€â”€ encoder.py
â”‚   â”‚   â”œâ”€â”€ decoder.py
â”‚   â”‚   â””â”€â”€ attr_gate.py
â”‚   â””â”€â”€ utils/                 # Data loading and utility functions
â”‚       â””â”€â”€ data_loader.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements_conda.yaml
â””â”€â”€ README.md
```

---

## âœ¨ Features

- Model-agnostic augmentation method.
- Learns graph-specific positional aspects (centralityâ€“similarity pairs).
- Automatically detects anchor-count via elbow point.
- Compatible with GNNs for node classification & link prediction.
- Significant performance boost on standard benchmarks (e.g., ogbn-mag, ogbl-ddi, Cora).

---

## âš™ï¸ Configuration

- Place raw graph datasets in `datasets/` directory.
- Precomputed centrality & similarity features should be stored under `attrs/`.
- You may modify the anchor aspects and centrality settings inside `generate_attributes.py`.

---

## ðŸ“¦ Dependencies

- Python â‰¥ 3.8
- PyTorch
- DGL or PyG
- NumPy
- SciPy
- tqdm

> See `requirements.txt` or `requirements_conda.yaml` for full environment setup.

---

## ðŸ§ª Examples

Run link prediction on Cora without original node attributes:
```bash
bash scripts/run_linkpred.sh
```

Train node classification with SCOUT-augmented attributes:
```bash
python src/core/train_nodeclf.py
```

---

## ðŸ§ª Experimental Environment

Experiments were run on the following machine:

```text
Machine: user@peace
GPU(s): 2x NVIDIA RTX A6000 (49GB each)
CUDA Version: 12.2
Driver Version: 535.247.01
```

Python environments were managed using both pip and conda:
- `pip install -r requirements.txt`
- `conda env create -f requirements_conda.yaml`

---

## ðŸ“„ License

This project is currently under review for WWW 2026. License details will be updated upon acceptance/publication.

---

